{"version":1,"kind":"Article","sha256":"dea33b014d159ab6fbff61802dae6782cd6277c2beb260a8ad3fc09f17047abe","slug":"project-design.risks-of-bias.validation-generalisability","location":"/project-design/risks-of-bias/validation-generalisability.md","dependencies":[],"frontmatter":{"title":"Validation and Generalisability","content_includes_title":false,"authors":[{"nameParsed":{"literal":"The Turing Way Community","given":"The Turing Way","family":"Community"},"name":"The Turing Way Community","id":"contributors-myst-generated-uid-0"}],"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"MIT","url":"https://opensource.org/licenses/MIT","name":"MIT License","free":true,"osi":true}},"github":"https://github.com/the-turing-way/the-turing-way","copyright":"2019-2025","numbering":{"title":{"offset":2}},"edit_url":"https://github.com/the-turing-way/the-turing-way/blob/main/book/website/project-design/risks-of-bias/validation-generalisability.md","exports":[{"format":"md","filename":"validation-generalisability.md","url":"/build/validation-generalis-eb81b294c6b7d82a2cb16a10b6dc879e.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Data analysis often involves making quantitative estimates of performance (such as assessing the accuracy of predictions), in a process called validation.\nPoor validation can lead to the research results being inaccurate, uninformative, or misleading.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"zmvxqFtITy"}],"key":"lXIuA8Nb12"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Validations are often weak due to the use of small and potentially non-representative samples.\nWhen working with sampled data, it is essential to extract the most information possible, which often means using some of the following techniques:","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"H51htSJJzh"}],"key":"afTVJRcjbY"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":8,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"(Stratified) Cross-validation","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"EvbxwiGvQ4"}],"key":"kIoFmOVbEa"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Bootstrapping (and other variability measures)","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"eqXLmIYsAq"}],"key":"TwRdoGK15Y"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"External validation","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"BAF0R3ELk0"}],"key":"LvJSQ6UyuN"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Statistical tests (hypothesis tests)","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"fgRSMeaWzP"}],"key":"DnfFpfc2LC"}],"key":"wPQUuNQqbk"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Such methods can help to evaluate the variability and generalisability of results.\nThis is particularly useful when comparing different modelling approaches or exposures, as without measuring the variability we cannot be certain whether ‘better’ results were simply caused by random chance.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"XvTQFCMy9Z"}],"key":"kpJcA50CRP"},{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"It is also important in validation to choose appropriate metrics.\nNo individual metric is able to assess all relevant aspects of performance, and as such it is far more informative to calculate several different metrics with different properties.\nThese should then ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"kOqtwwihxR"},{"type":"emphasis","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"all","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"D9Ug7Ax2TW"}],"key":"nCi51zWZxW"},{"type":"text","value":" be reported on, without simply cherry-picking the ones which portray the best performance.\nIt is not always clear which metrics are most useful for a given task, so it may be useful to refer to any ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"N7CcBwABd6"},{"type":"link","url":"https://www.nature.com/articles/s41592-023-02151-z","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"specific guidance","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"z8iql0g3wT"}],"urlSource":"https://www.nature.com/articles/s41592-023-02151-z","key":"QfO0C4qmLD"},{"type":"text","value":" for the field.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"XbO0ynHuFo"}],"key":"eEbbYXb6Yi"},{"type":"paragraph","position":{"start":{"line":22,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"When working with imbalanced data, it is also important to consider the effect this has on the results.\nFor example, if a dataset contains 99% cats and 1% dogs, then a classification model can simply say everything is a cat to get 99% accuracy.\nSuch a model is completely useless, and this would be obvious if we used a ","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"bIFdqn03Xp"},{"type":"emphasis","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"balanced accuracy","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"xenpDFUosT"}],"key":"IRPpM9T8D7"},{"type":"text","value":", which would give a score of 50%.\nSimilar effects also apply to other metrics, and these can similarly be balanced based on the data available.","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"Os6nbAqWLR"}],"key":"WIPRhvAvdL"}],"key":"frnajAqerv"}],"key":"LRDfZM7TuO"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Confounding Variables","url":"/project-design/risks-of-bias/confounding-variables","group":"The Turing Way"},"next":{"title":"Discrimination and Bias","url":"/project-design/risks-of-bias/discrimination-bias","group":"The Turing Way"}}},"domain":"http://localhost:3001"}